# ğŸ—ï¸ INFRAESTRUCTURA DEL PROYECTO - GUÃA CONCEPTUAL

## ğŸ“– IntroducciÃ³n

Este documento explica **exclusivamente los conceptos de infraestructura** utilizados en el proyecto, sin entrar en detalles de cÃ³digo de backend, frontend o base de datos. El objetivo es entender **cÃ³mo y por quÃ©** se despliega la aplicaciÃ³n de esta manera.

---

## ğŸ¯ Â¿QuÃ© es Infraestructura?

La **infraestructura** se refiere a todos los componentes y tecnologÃ­as que permiten que una aplicaciÃ³n se ejecute, sea accesible y funcione correctamente. Incluye:

- **Contenedores:** CÃ³mo empaquetamos la aplicaciÃ³n
- **OrquestaciÃ³n:** CÃ³mo gestionamos mÃºltiples contenedores
- **Redes:** CÃ³mo se comunican los servicios
- **Almacenamiento:** CÃ³mo persisten los datos
- **Escalabilidad:** CÃ³mo manejamos mÃ¡s usuarios
- **Alta Disponibilidad:** CÃ³mo evitamos caÃ­das del sistema

---

## ğŸ“¦ Nivel 1: Contenedores con Docker

### Â¿QuÃ© es Docker?

Imagina que quieres enviar tu aplicaciÃ³n a otra persona. Sin Docker, tendrÃ­as que darle:
- Tu cÃ³digo
- Las instrucciones: "Instala Node.js versiÃ³n 20"
- "Instala PostgreSQL versiÃ³n 16"
- "Instala estas 50 librerÃ­as"
- "Configura estos archivos"
- Y rezar porque todo funcione igual en su computadora

Con Docker, creas una **"caja mÃ¡gica"** que contiene:
- Tu cÃ³digo âœ…
- Node.js 20 âœ…
- Todas las librerÃ­as âœ…
- Toda la configuraciÃ³n âœ…

La persona solo necesita Docker y ejecutar un comando. **GarantÃ­a:** Si funciona en tu mÃ¡quina, funciona en cualquier mÃ¡quina.

### Conceptos Clave de Docker

#### 1. **Imagen (Image)**

Una **plantilla inmutable** que contiene todo lo necesario para ejecutar tu aplicaciÃ³n.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      IMAGEN DOCKER              â”‚
â”‚  (Plantilla - Solo Lectura)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - Sistema Operativo Base       â”‚
â”‚    (Alpine Linux - 5MB)         â”‚
â”‚  - Node.js 20                   â”‚
â”‚  - CÃ³digo de tu aplicaciÃ³n      â”‚
â”‚  - Dependencias (npm packages)  â”‚
â”‚  - ConfiguraciÃ³n                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**AnalogÃ­a:** Una imagen es como un **molde para hacer galletas**. El molde siempre es el mismo.

#### 2. **Contenedor (Container)**

Una **instancia en ejecuciÃ³n** de una imagen. Puedes crear mÃºltiples contenedores de la misma imagen.

```
Imagen (Molde)
    â”‚
    â”œâ”€â”€â†’ Contenedor 1 (Galleta)
    â”œâ”€â”€â†’ Contenedor 2 (Galleta)
    â””â”€â”€â†’ Contenedor 3 (Galleta)
```

**Diferencias importantes:**

| Aspecto | Imagen | Contenedor |
|---------|--------|------------|
| **Estado** | Inmutable (no cambia) | Mutable (puede cambiar) |
| **Cantidad** | Una por versiÃ³n | Muchos de una imagen |
| **AnalogÃ­a** | Receta de cocina | Plato de comida |

#### 3. **Dockerfile**

Un **script** que define cÃ³mo construir una imagen.

```dockerfile
# Ejemplo simplificado
FROM node:20-alpine          # Base: Node.js 20 en Alpine Linux
WORKDIR /app                 # Directorio de trabajo
COPY . .                     # Copiar cÃ³digo
RUN npm install              # Instalar dependencias
CMD ["node", "server.js"]    # Comando para iniciar
```

**Â¿Por quÃ© Alpine?**
- Linux normal: ~200MB
- Alpine Linux: ~5MB (40x mÃ¡s pequeÃ±o)
- Resultado: ImÃ¡genes mÃ¡s rÃ¡pidas de descargar y desplegar

#### 4. **Volumen (Volume)**

Un **almacenamiento persistente** que sobrevive incluso si el contenedor se elimina.

```
Sin Volumen:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Contenedor  â”‚ â†’ Datos guardados aquÃ­
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â””â”€â”€â†’ ELIMINAR CONTENEDOR = PERDER DATOS âŒ

Con Volumen:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Contenedor  â”‚â”€â”€â”€â”€â–¶â”‚  Volumen    â”‚ â†’ Datos aquÃ­
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                    â”‚
     â””â”€â”€â†’ ELIMINAR        â””â”€â”€â†’ DATOS PERSISTEN âœ…
```

**En el proyecto:** El volumen `postgres_data` guarda los 30 PokÃ©mon. Si reinicias Docker, los datos siguen ahÃ­.

#### 5. **Red (Network)**

Una **red virtual** que permite que los contenedores se comuniquen entre sÃ­.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DOCKER NETWORK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  Frontend    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Backend    â”‚                 â”‚
â”‚  â”‚  Contenedor  â”‚ HTTP    â”‚  Contenedor  â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                  â”‚                          â”‚
â”‚                                  â”‚ SQL                      â”‚
â”‚                                  â–¼                          â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                           â”‚  PostgreSQL  â”‚                 â”‚
â”‚                           â”‚  Contenedor  â”‚                 â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Magia:** Dentro de la red, los contenedores se llaman por nombre:
- Frontend se conecta a `http://backend:4000`
- Backend se conecta a `postgres:5432`

Docker resuelve automÃ¡ticamente estos nombres a las IPs internas.

### Multi-Stage Build

Una tÃ©cnica para crear imÃ¡genes **mÃ¡s pequeÃ±as y seguras**.

```dockerfile
# ETAPA 1: ConstrucciÃ³n (Build)
FROM node:20 AS builder
WORKDIR /app
COPY . .
RUN npm install        # Instala TODO (dev + prod)
RUN npm run build      # Compila la aplicaciÃ³n

# ETAPA 2: ProducciÃ³n
FROM nginx:alpine      # Imagen ligera
COPY --from=builder /app/dist /usr/share/nginx/html  # Solo archivos finales
# NO copia node_modules, ni cÃ³digo fuente, ni herramientas de build
```

**Resultado:**
- Imagen con todo: 450MB âŒ
- Imagen multi-stage: 45MB âœ… (90% mÃ¡s pequeÃ±a)

**Beneficios:**
1. **Velocidad:** MÃ¡s rÃ¡pido de descargar y desplegar
2. **Seguridad:** Menos paquetes = menos vulnerabilidades
3. **Costo:** Menos almacenamiento en registries

---

## ğŸ™ Nivel 2: OrquestaciÃ³n con Docker Compose

### Â¿QuÃ© es Docker Compose?

Docker maneja **un contenedor a la vez**. Â¿Y si tu aplicaciÃ³n necesita 3 contenedores (frontend, backend, database)?

Docker Compose te permite:
- Definir mÃºltiples servicios en un archivo YAML
- Iniciarlos todos con un comando
- Gestionar sus conexiones automÃ¡ticamente

### Arquitectura de Docker Compose

```
docker-compose.yml (Orquestador)
â”‚
â”œâ”€â”€â”€ Service 1: postgres
â”‚    â”œâ”€â”€ Usa imagen: postgres:16-alpine
â”‚    â”œâ”€â”€ Puerto: 5432
â”‚    â”œâ”€â”€ Volumen: postgres_data
â”‚    â””â”€â”€ Red: pokemon_network
â”‚
â”œâ”€â”€â”€ Service 2: backend
â”‚    â”œâ”€â”€ Usa imagen: pokemon-backend
â”‚    â”œâ”€â”€ Puerto: 4000
â”‚    â”œâ”€â”€ Espera a: postgres (depends_on)
â”‚    â””â”€â”€ Red: pokemon_network
â”‚
â””â”€â”€â”€ Service 3: frontend
     â”œâ”€â”€ Usa imagen: pokemon-frontend
     â”œâ”€â”€ Puerto: 3000 â†’ 80
     â”œâ”€â”€ Espera a: backend
     â””â”€â”€ Red: pokemon_network
```

### Conceptos Clave de Docker Compose

#### 1. **Services**

Un "service" es bÃ¡sicamente un contenedor con configuraciÃ³n.

```yaml
services:
  backend:                # Nombre del servicio
    build: .              # Construir desde Dockerfile
    ports:
      - "4000:4000"       # Puerto HOST:CONTENEDOR
    environment:
      DB_HOST: postgres   # Variables de entorno
```

#### 2. **depends_on (Orden de Inicio)**

```yaml
backend:
  depends_on:
    postgres:
      condition: service_healthy
```

**Â¿QuÃ© hace esto?**

```
Inicio normal (sin depends_on):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Postgres â”‚  â”‚ Backend â”‚  â”‚Frontend â”‚
â”‚ Inicia  â”‚  â”‚ Inicia  â”‚  â”‚ Inicia  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚            â”‚             â”‚
     â”‚            â””â”€â”€Xâ”€â”€ ERROR: No puede conectar a postgres
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tarda 10 segundos en estar listo

Con depends_on + health check:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Postgres â”‚
â”‚ Inicia  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚ 10 segundos...
     â”œâ”€â”€â”€ Health Check: âœ… LISTO
     â”‚
     â”œâ”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚    â”‚ Backend â”‚
     â”‚    â”‚ Inicia  â”‚
     â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚         â”‚ Backend conecta exitosamente
     â”‚         â”œâ”€â”€â”€ Health Check: âœ… LISTO
     â”‚         â”‚
     â”‚         â””â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚              â”‚Frontend â”‚
     â”‚              â”‚ Inicia  â”‚
     â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â””â”€â”€ Orden garantizado âœ…
```

#### 3. **Health Checks**

Un health check es una **prueba automÃ¡tica** que Docker ejecuta para saber si un servicio estÃ¡ funcionando.

```yaml
healthcheck:
  test: ["CMD-SHELL", "pg_isready -U postgres"]
  interval: 10s     # Revisar cada 10 segundos
  timeout: 5s       # Esperar mÃ¡ximo 5 segundos
  retries: 5        # Intentar 5 veces antes de declarar "unhealthy"
```

**Estados posibles:**
- `starting`: ReciÃ©n iniciado, aÃºn no se revisa
- `healthy`: âœ… PasÃ³ el health check
- `unhealthy`: âŒ FallÃ³ el health check

**Ciclo de vida:**

```
Contenedor inicia
    â†“
[starting] â”€â”€â”€â”€â†’ Espera initialDelaySeconds
    â†“
Ejecuta health check cada "interval" segundos
    â†“
Â¿PasÃ³? â”€â”€â”€ SÃ â”€â”€â†’ [healthy] âœ…
    â”‚
    NO
    â†“
Reintentar (hasta "retries" veces)
    â†“
Â¿Sigue fallando? â”€â”€â”€ SÃ â”€â”€â†’ [unhealthy] âŒ
                                â†“
                          Reiniciar contenedor
```

#### 4. **Ports (Mapeo de Puertos)**

```yaml
ports:
  - "3000:80"
    â”‚    â”‚
    â”‚    â””â”€â”€ Puerto DENTRO del contenedor
    â””â”€â”€â”€â”€â”€â”€ Puerto en TU COMPUTADORA (host)
```

**Â¿Por quÃ© son diferentes?**

```
Tu computadora (host)
    â†“ localhost:3000
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Docker Network                â”‚
â”‚                                 â”‚
â”‚   Contenedor Frontend           â”‚
â”‚   Nginx escucha en puerto 80 â—„â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Esto permite:
- Tener mÃºltiples contenedores usando el mismo puerto interno (80)
- Pero exponerlos en diferentes puertos externos (3000, 4000, 5000...)

#### 5. **Volumes (Persistencia)**

```yaml
volumes:
  postgres_data:      # Nombre del volumen
    driver: local     # Almacenar en disco local
```

**Â¿DÃ³nde se guarda?**

```bash
# Linux
/var/lib/docker/volumes/pokemon_postgres_data/_data/

# Ver contenido
docker volume inspect pokemon_postgres_data
```

**Ciclo de vida:**

```
docker-compose up
    â†“
Crea volumen (si no existe)
    â†“
Monta volumen en contenedor
    â†“
Postgres guarda datos en volumen
    â†“
docker-compose down
    â†“
Contenedor eliminado âœ“
Volumen PERSISTE âœ“ â†â”€â”€ DATOS SIGUEN AHÃ
    â†“
docker-compose up (de nuevo)
    â†“
Monta el MISMO volumen
    â†“
Postgres ve los datos anteriores âœ…
```

#### 6. **Networks (Redes)**

```yaml
networks:
  pokemon_network:
    driver: bridge
```

**Â¿QuÃ© es "bridge"?**

Es una red virtual que actÃºa como un **switch** entre contenedores:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Bridge Network â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                               â”‚
â”‚  Contenedor 1          Contenedor 2          Contenedor 3    â”‚
â”‚  (frontend)            (backend)             (postgres)       â”‚
â”‚  IP: 172.18.0.2        IP: 172.18.0.3        IP: 172.18.0.4  â”‚
â”‚       â”‚                      â”‚                     â”‚          â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                          Switch                               â”‚
â”‚                      (DNS interno)                            â”‚
â”‚                                                               â”‚
â”‚  frontend puede llamar a "backend" en vez de 172.18.0.3      â”‚
â”‚  backend puede llamar a "postgres" en vez de 172.18.0.4      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Aislamiento:** Otros contenedores en tu computadora **no pueden** acceder a esta red a menos que estÃ©n explÃ­citamente conectados.

---

## â˜¸ï¸ Nivel 3: OrquestaciÃ³n con Kubernetes

### Â¿Por quÃ© Kubernetes si ya tenemos Docker Compose?

Docker Compose es genial para **desarrollo local**, pero en **producciÃ³n** necesitas:

| Necesidad | Docker Compose | Kubernetes |
|-----------|----------------|------------|
| **MÃºltiples servidores** | âŒ Solo una mÃ¡quina | âœ… Cluster de nodos |
| **Auto-recuperaciÃ³n** | âš ï¸ BÃ¡sico | âœ… Avanzado |
| **Escalado automÃ¡tico** | âŒ Manual | âœ… AutomÃ¡tico (HPA) |
| **Rolling updates** | âŒ Downtime | âœ… Sin downtime |
| **Load balancing** | âŒ Manual | âœ… Integrado |
| **GestiÃ³n de secretos** | âš ï¸ Variables env | âœ… Secrets encriptados |

### Arquitectura de Kubernetes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ KUBERNETES CLUSTER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONTROL PLANE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  (Cerebro del cluster - Gestionado por Azure/K8s)   â”‚      â”‚
â”‚  â”‚                                                       â”‚      â”‚
â”‚  â”‚  â€¢ API Server: Recibe comandos kubectl               â”‚      â”‚
â”‚  â”‚  â€¢ Scheduler: Decide dÃ³nde colocar pods              â”‚      â”‚
â”‚  â”‚  â€¢ Controller Manager: Mantiene estado deseado       â”‚      â”‚
â”‚  â”‚  â€¢ etcd: Base de datos del estado del cluster        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                            â”‚                                    â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚              â”‚             â”‚             â”‚                     â”‚
â”‚         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚ NODE 1  â”‚   â”‚ NODE 2  â”‚   â”‚ NODE 3  â”‚              â”‚
â”‚         â”‚ (VM)    â”‚   â”‚ (VM)    â”‚   â”‚ (VM)    â”‚              â”‚
â”‚         â”‚         â”‚   â”‚         â”‚   â”‚         â”‚              â”‚
â”‚         â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚              â”‚
â”‚         â”‚ â”‚ Pod â”‚ â”‚   â”‚ â”‚ Pod â”‚ â”‚   â”‚ â”‚ Pod â”‚ â”‚              â”‚
â”‚         â”‚ â””â”€â”€â”€â”€â”€â”˜ â”‚   â”‚ â””â”€â”€â”€â”€â”€â”˜ â”‚   â”‚ â””â”€â”€â”€â”€â”€â”˜ â”‚              â”‚
â”‚         â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚              â”‚
â”‚         â”‚ â”‚ Pod â”‚ â”‚   â”‚ â”‚ Pod â”‚ â”‚   â”‚ â”‚ Pod â”‚ â”‚              â”‚
â”‚         â”‚ â””â”€â”€â”€â”€â”€â”˜ â”‚   â”‚ â””â”€â”€â”€â”€â”€â”˜ â”‚   â”‚ â””â”€â”€â”€â”€â”€â”˜ â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Conceptos Clave de Kubernetes

#### 1. **Pod**

La **unidad mÃ­nima** desplegable en Kubernetes. Contiene uno o mÃ¡s contenedores.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          POD                â”‚
â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Contenedor Backend â”‚   â”‚  â† Usualmente 1 contenedor por pod
â”‚  â”‚  (pokemon-backend)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚
â”‚  IP: 10.244.1.5             â”‚
â”‚  Namespace: pokemon-app     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pod vs Contenedor:**

| Aspecto | Contenedor | Pod |
|---------|------------|-----|
| **DefiniciÃ³n** | Proceso aislado | Grupo de contenedores |
| **Red** | IP del host | IP propia del pod |
| **VolÃºmenes** | Monta volÃºmenes | Todos los contenedores comparten volÃºmenes |
| **Ciclo de vida** | Parte del pod | Unidad de despliegue |

**Â¿Por quÃ© no desplegar contenedores directamente?**

Kubernetes necesita informaciÃ³n adicional:
- Â¿DÃ³nde ejecutar el contenedor?
- Â¿CuÃ¡nta CPU/memoria necesita?
- Â¿CÃ³mo reiniciarlo si falla?
- Â¿CÃ³mo comunicarse con Ã©l?

El pod es el "envoltorio" que contiene esta informaciÃ³n.

#### 2. **Deployment**

Un **controlador** que gestiona mÃºltiples rÃ©plicas de pods.

```
Deployment: backend (spec: 3 rÃ©plicas)
    â”‚
    â”œâ”€â”€â†’ Pod 1 (backend-abc123)
    â”œâ”€â”€â†’ Pod 2 (backend-def456)
    â””â”€â”€â†’ Pod 3 (backend-ghi789)
```

**Â¿QuÃ© hace el Deployment?**

```
Estado Deseado (Declarativo):
"Quiero 3 rÃ©plicas del backend ejecutÃ¡ndose"

    â†“

Kubernetes trabaja para mantener ese estado:

1. Crea 3 pods âœ“
2. Uno falla â†’ Crea reemplazo automÃ¡ticamente âœ“
3. Actualizas imagen â†’ Rolling update sin downtime âœ“
4. Escalas a 5 â†’ Crea 2 pods adicionales âœ“
5. Reduces a 2 â†’ Elimina 1 pod gradualmente âœ“
```

**Ejemplo de Deployment:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
spec:
  replicas: 3                    # â† Estado deseado
  selector:
    matchLabels:
      app: backend
  template:                      # â† Plantilla del pod
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: pokemon-backend:latest
        ports:
        - containerPort: 4000
```

#### 3. **Service**

Un **balanceador de carga interno** que expone pods.

**Problema:** Los pods tienen IPs dinÃ¡micas que cambian al reiniciarse.

```
Pod 1: 10.244.1.5 â”€â”€â”
Pod 2: 10.244.2.8 â”€â”€â”¼â”€â”€ Â¿A cuÃ¡l conectarse?
Pod 3: 10.244.3.2 â”€â”€â”˜
```

**SoluciÃ³n:** El Service crea una **IP estable** y balancea automÃ¡ticamente.

```
Service: backend-service (IP: 10.96.185.123)
    â”‚
    â”œâ”€â”€â†’ Pod 1: 10.244.1.5
    â”œâ”€â”€â†’ Pod 2: 10.244.2.8
    â””â”€â”€â†’ Pod 3: 10.244.3.2

Frontend conecta a: backend-service:4000
Service distribuye requests entre los 3 pods âœ…
```

**Tipos de Services:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ClusterIP (Predeterminado)                              â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                               â”‚
â”‚ IP interna del cluster                                  â”‚
â”‚ Solo accesible DENTRO de Kubernetes                     â”‚
â”‚                                                          â”‚
â”‚ Uso: postgres-service                                   â”‚
â”‚ Nadie fuera del cluster necesita acceder a la BD        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NodePort                                                â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                              â”‚
â”‚ Expone puerto en cada nodo del cluster                  â”‚
â”‚ Accesible en: <NODE_IP>:<NODE_PORT>                     â”‚
â”‚                                                          â”‚
â”‚ Uso: Testing/desarrollo                                 â”‚
â”‚ Rango de puertos: 30000-32767                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LoadBalancer                                            â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                              â”‚
â”‚ Crea un balanceador de carga EXTERNO                    â”‚
â”‚ Asigna IP pÃºblica (en cloud providers)                  â”‚
â”‚                                                          â”‚
â”‚ Uso: backend-service, frontend-service                  â”‚
â”‚ Accesible desde Internet âœ…                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 4. **ConfigMap y Secret**

Ambos almacenan configuraciÃ³n, pero con diferentes niveles de seguridad.

**ConfigMap:** Datos **no sensibles** (pÃºblicos)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  DATABASE_NAME: pokemon_db      # OK mostrar
  API_PORT: "4000"               # OK mostrar
  ENVIRONMENT: production        # OK mostrar
```

**Secret:** Datos **sensibles** (privados)

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
type: Opaque
stringData:
  POSTGRES_PASSWORD: postgres123  # âŒ NO mostrar en logs
  API_KEY: sk_live_xyz123         # âŒ NO mostrar en Git
```

**Diferencias:**

| Aspecto | ConfigMap | Secret |
|---------|-----------|--------|
| **Contenido** | No sensible | Sensible (passwords, tokens) |
| **CodificaciÃ³n** | Texto plano | Base64 |
| **En logs** | Visible | Ocultado |
| **En Git** | OK commitear | âŒ NUNCA commitear |
| **EncriptaciÃ³n** | No | SÃ­ (en etcd) |

**Uso en pods:**

```yaml
env:
- name: DB_NAME
  valueFrom:
    configMapKeyRef:       # Leer desde ConfigMap
      name: app-config
      key: DATABASE_NAME
- name: DB_PASSWORD
  valueFrom:
    secretKeyRef:          # Leer desde Secret
      name: postgres-secret
      key: POSTGRES_PASSWORD
```

#### 5. **PersistentVolumeClaim (PVC)**

Un **disco virtual** que solicita almacenamiento persistente.

```
PersistentVolumeClaim (PVC)
"Necesito 1GB de almacenamiento"
    â”‚
    â†“
Kubernetes busca o crea un PersistentVolume (PV)
    â”‚
    â†“
PV (Volumen fÃ­sico)
Disco en: Azure Disk / AWS EBS / GCP Persistent Disk
    â”‚
    â†“
Se monta en el pod
    â”‚
    â†“
PostgreSQL guarda datos aquÃ­
```

**Sin PVC:**

```
Pod 1 (postgres) â†’ Datos en disco efÃ­mero
    â”‚
    â””â”€â”€â†’ Pod se reinicia
           â”‚
           â””â”€â”€â†’ DATOS PERDIDOS âŒ
```

**Con PVC:**

```
Pod 1 (postgres) â”€â”€â†’ PVC â”€â”€â†’ Datos en disco persistente
    â”‚                          (Azure Disk)
    â””â”€â”€â†’ Pod se reinicia
           â”‚
           â”œâ”€â”€â†’ Nuevo pod se crea
           â”‚
           â””â”€â”€â†’ Se monta el MISMO PVC
                  â”‚
                  â””â”€â”€â†’ DATOS INTACTOS âœ…
```

**DefiniciÃ³n:**

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
spec:
  accessModes:
    - ReadWriteOnce     # Solo un pod puede escribir a la vez
  resources:
    requests:
      storage: 1Gi      # Solicitar 1 Gigabyte
  storageClassName: standard  # Tipo de disco
```

#### 6. **Namespace**

Un **espacio de nombres** para aislar recursos lÃ³gicamente.

```
Kubernetes Cluster
â”‚
â”œâ”€â”€â”€ Namespace: default
â”‚    â”œâ”€â”€ Deployment: nginx
â”‚    â””â”€â”€ Service: nginx-service
â”‚
â”œâ”€â”€â”€ Namespace: pokemon-app  â† Nuestro proyecto
â”‚    â”œâ”€â”€ Deployment: backend (3 pods)
â”‚    â”œâ”€â”€ Deployment: frontend (1 pod)
â”‚    â”œâ”€â”€ Deployment: postgres (1 pod)
â”‚    â”œâ”€â”€ Service: backend-service
â”‚    â”œâ”€â”€ Service: frontend-service
â”‚    â””â”€â”€ Service: postgres-service
â”‚
â””â”€â”€â”€ Namespace: monitoring
     â”œâ”€â”€ Deployment: prometheus
     â””â”€â”€ Service: grafana
```

**Beneficios:**

1. **OrganizaciÃ³n:** Agrupar recursos relacionados
2. **Aislamiento:** Los recursos en diferentes namespaces no se ven
3. **Cuotas:** Limitar recursos por namespace (ej: max 10 pods)
4. **Permisos:** Dar acceso solo a ciertos namespaces

**ComunicaciÃ³n entre namespaces:**

```
Mismo namespace:
frontend â†’ backend-service:4000 âœ…

Diferente namespace:
frontend â†’ backend-service.pokemon-app.svc.cluster.local:4000 âœ…
            â”‚              â”‚          â”‚       â”‚
            â”” Service      â”” Namespaceâ”” "svc" â”” dominio interno
```

### Escalabilidad en Kubernetes

#### Escalado Manual

```bash
kubectl scale deployment backend --replicas=5
```

**Â¿QuÃ© pasa internamente?**

```
Estado actual: 3 rÃ©plicas
Estado deseado: 5 rÃ©plicas
    â†“
Kubernetes calcula: Necesito 2 pods mÃ¡s
    â†“
1. Crea 2 pods nuevos
2. Espera a que estÃ©n "Ready" (health checks)
3. Service empieza a enviar trÃ¡fico a los 5 pods
    â†“
Sin downtime âœ…
```

#### Horizontal Pod Autoscaler (HPA)

**Escalado automÃ¡tico** basado en mÃ©tricas.

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend
  minReplicas: 3              # MÃ­nimo 3 pods siempre
  maxReplicas: 10             # MÃ¡ximo 10 pods
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # Escalar si CPU > 70%
```

**Funcionamiento:**

```
1. Bajo trÃ¡fico (CPU: 20%)
   â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”
   â”‚ P â”‚ â”‚ P â”‚ â”‚ P â”‚  â† 3 rÃ©plicas
   â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜

2. TrÃ¡fico aumenta (CPU: 80%)
   HPA detecta: CPU > 70% â—
   â†“
   Escala a 6 rÃ©plicas â¬†ï¸
   â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”
   â”‚ P â”‚ â”‚ P â”‚ â”‚ P â”‚ â”‚ P â”‚ â”‚ P â”‚ â”‚ P â”‚
   â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜
   CPU baja a ~40% âœ“

3. TrÃ¡fico disminuye (CPU: 30%)
   HPA detecta: CPU < 70% durante 5 minutos
   â†“
   Reduce a 3 rÃ©plicas â¬‡ï¸
   â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”
   â”‚ P â”‚ â”‚ P â”‚ â”‚ P â”‚
   â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜
```

### Self-Healing (Auto-RecuperaciÃ³n)

Kubernetes monitorea constantemente los pods y los **repara automÃ¡ticamente**.

#### Liveness Probe

Detecta si un contenedor estÃ¡ **vivo** (funcionando internamente).

```yaml
livenessProbe:
  httpGet:
    path: /health        # Llamar GET /health
    port: 4000
  initialDelaySeconds: 30  # Esperar 30s antes de empezar
  periodSeconds: 10        # Revisar cada 10 segundos
  failureThreshold: 3      # Fallar 3 veces = reiniciar
```

**Flujo:**

```
Pod inicia
    â†“
Espera 30 segundos (initialDelaySeconds)
    â†“
Cada 10 segundos ejecuta: GET /health
    â†“
Â¿Responde 200 OK?
    â”‚
    â”œâ”€â”€ SÃ â†’ Pod estÃ¡ vivo âœ… (continuar monitoreando)
    â”‚
    â””â”€â”€ NO â†’ Contador de fallos++
               â”‚
               â””â”€â”€ Â¿Fallos >= 3?
                       â”‚
                       â””â”€â”€ SÃ â†’ âš ï¸ REINICIAR CONTENEDOR
```

**Ejemplo real:**

```
10:00:00 - Liveness: 200 OK âœ“
10:00:10 - Liveness: 200 OK âœ“
10:00:20 - Liveness: 200 OK âœ“
10:00:30 - Liveness: 500 ERROR âœ— (fallo 1/3)
10:00:40 - Liveness: 500 ERROR âœ— (fallo 2/3)
10:00:50 - Liveness: 500 ERROR âœ— (fallo 3/3)
10:01:00 - âš ï¸ REINICIANDO CONTENEDOR...
10:01:15 - Nuevo contenedor iniciado
10:01:45 - Liveness: 200 OK âœ“ (recuperado)
```

#### Readiness Probe

Detecta si un contenedor estÃ¡ **listo** para recibir trÃ¡fico.

```yaml
readinessProbe:
  httpGet:
    path: /health
    port: 4000
  initialDelaySeconds: 5
  periodSeconds: 5
```

**Diferencia con Liveness:**

| Aspecto | Liveness Probe | Readiness Probe |
|---------|---------------|-----------------|
| **Pregunta** | Â¿EstÃ¡ vivo? | Â¿EstÃ¡ listo? |
| **AcciÃ³n si falla** | Reiniciar contenedor | Quitar de Service (no enviar trÃ¡fico) |
| **Ejemplo** | Proceso crashed | Cargando datos iniciales |

**Flujo:**

```
Pod inicia
    â†“
Estado: Not Ready (no recibe trÃ¡fico)
    â†“
Readiness Probe cada 5 segundos
    â†“
Â¿Responde 200 OK?
    â”‚
    â”œâ”€â”€ SÃ â†’ Pod pasa a Ready âœ…
    â”‚        Service empieza a enviar trÃ¡fico
    â”‚
    â””â”€â”€ NO â†’ Pod sigue Not Ready
             Service NO envÃ­a trÃ¡fico (protege de errores)
```

**Caso de uso real:**

```
Backend inicia
    â†“
Necesita conectarse a PostgreSQL (tarda 10 segundos)
    â†“
Durante esos 10 segundos:
- Liveness: OK (proceso estÃ¡ vivo)
- Readiness: NO (no puede responder requests aÃºn)
- Service: No envÃ­a trÃ¡fico a este pod
    â†“
DespuÃ©s de conectarse a PostgreSQL:
- Readiness: OK âœ“
- Service: Empieza a enviar trÃ¡fico âœ“
```

### Rolling Updates (Actualizaciones sin Downtime)

Actualizar la aplicaciÃ³n **sin interrumpir el servicio**.

```yaml
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 1          # MÃ¡ximo 1 pod extra durante update
    maxUnavailable: 1    # MÃ¡ximo 1 pod no disponible
```

**Flujo de actualizaciÃ³n:**

```
Estado inicial: 3 pods con versiÃ³n v1
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜

Comando: kubectl set image deployment/backend backend=backend:v2

Paso 1: Crear 1 pod nuevo (maxSurge: 1)
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v2  â”‚ â† Nuevo
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜

Paso 2: Esperar a que v2 estÃ© Ready
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v2âœ“ â”‚ â† Ready
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜

Paso 3: Eliminar 1 pod v1 (maxUnavailable: 1)
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”
â”‚ v1  â”‚ â”‚ v1  â”‚          â”‚ v2âœ“ â”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”˜

Paso 4: Crear otro pod v2
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v2  â”‚ â”‚ v2âœ“ â”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜

Paso 5: Esperar Ready
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
â”‚ v1  â”‚ â”‚ v1  â”‚ â”‚ v2âœ“ â”‚ â”‚ v2âœ“ â”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜

Paso 6: Eliminar otro pod v1
â”Œâ”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
â”‚ v1  â”‚          â”‚ v2âœ“ â”‚ â”‚ v2âœ“ â”‚
â””â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜

Paso 7: Crear Ãºltimo pod v2
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
â”‚ v1  â”‚ â”‚ v2  â”‚ â”‚ v2âœ“ â”‚ â”‚ v2âœ“ â”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜

Paso 8: Esperar Ready y eliminar Ãºltimo v1
         â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
         â”‚ v2âœ“ â”‚ â”‚ v2âœ“ â”‚ â”‚ v2âœ“ â”‚
         â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜

âœ… ActualizaciÃ³n completa sin downtime
```

**Durante todo el proceso:**
- Siempre hay al menos 2 pods funcionando
- El Service continÃºa enviando trÃ¡fico
- Los usuarios no notan la actualizaciÃ³n

---

## â˜ï¸ Nivel 4: Cloud Computing con Azure

### Â¿Por quÃ© Azure (o cualquier Cloud)?

**Problema local:**
- Tu aplicaciÃ³n corre en tu laptop
- Solo accesible cuando tu laptop estÃ¡ encendida
- Solo accesible en tu red local
- Si tu laptop se rompe â†’ aplicaciÃ³n cae

**SoluciÃ³n Cloud:**
- AplicaciÃ³n corre en data centers de Azure (24/7/365)
- Accesible desde cualquier parte del mundo
- MÃºltiples rÃ©plicas en diferentes servidores
- Si un servidor falla â†’ otros continÃºan

### Azure Kubernetes Service (AKS)

**AKS** es Kubernetes **administrado por Microsoft**.

```
Kubernetes "vanilla" (hazlo tÃº mismo):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TÃš gestionas:                          â”‚
â”‚ â€¢ Instalar Kubernetes                  â”‚
â”‚ â€¢ Configurar master nodes              â”‚
â”‚ â€¢ Configurar worker nodes              â”‚
â”‚ â€¢ Actualizar versiones                 â”‚
â”‚ â€¢ Parches de seguridad                 â”‚
â”‚ â€¢ Backups                              â”‚
â”‚ â€¢ Monitoreo                            â”‚
â”‚ â€¢ Alta disponibilidad                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Tiempo: DÃ­as/semanas â°
Complejidad: Alta ğŸ”´

AKS (Azure Kubernetes Service):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AZURE gestiona:                        â”‚
â”‚ â€¢ Master node âœ… (gratis)              â”‚
â”‚ â€¢ Actualizaciones âœ…                   â”‚
â”‚ â€¢ Parches de seguridad âœ…              â”‚
â”‚ â€¢ Alta disponibilidad âœ…               â”‚
â”‚                                        â”‚
â”‚ TÃš gestionas:                          â”‚
â”‚ â€¢ Tus aplicaciones (deployments)      â”‚
â”‚ â€¢ NÃºmero de nodos worker              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Tiempo: Minutos â±ï¸
Complejidad: Baja ğŸŸ¢
```

### Azure Container Registry (ACR)

Un **Docker Hub privado** en Azure.

```
Flujo de despliegue:

1. Desarrollo local
   docker build -t pokemon-backend:v1 .

2. Push a ACR
   docker tag pokemon-backend:v1 myregistry.azurecr.io/pokemon-backend:v1
   docker push myregistry.azurecr.io/pokemon-backend:v1

3. AKS pull desde ACR
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   ACR (Registry)    â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
   â”‚  â”‚ backend:v1   â”‚   â”‚
   â”‚  â”‚ frontend:v1  â”‚   â”‚
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ pull
             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   AKS (Cluster)     â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
   â”‚  â”‚ 3 Pods       â”‚   â”‚
   â”‚  â”‚ backend:v1   â”‚   â”‚
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Â¿Por quÃ© no Docker Hub pÃºblico?**

| Aspecto | Docker Hub | ACR |
|---------|------------|-----|
| **Seguridad** | PÃºblico (cualquiera puede ver) | Privado (solo tu equipo) |
| **Velocidad** | Internet pÃºblico | Red interna Azure (rÃ¡pido) |
| **Costo** | Gratis (lÃ­mites de pull) | Pago (~$5/mes Basic) |
| **IntegraciÃ³n AKS** | Manual | AutomÃ¡tica |

### Azure Database for PostgreSQL

Base de datos **administrada** por Azure.

```
PostgreSQL en contenedor (nuestro enfoque local):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TÃš gestionas:                          â”‚
â”‚ â€¢ Backups manualmente                  â”‚
â”‚ â€¢ Actualizaciones de PostgreSQL        â”‚
â”‚ â€¢ ReplicaciÃ³n (si quieres HA)          â”‚
â”‚ â€¢ Monitoreo de disco                   â”‚
â”‚ â€¢ Seguridad (firewall, SSL)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Azure Database for PostgreSQL:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AZURE gestiona:                        â”‚
â”‚ â€¢ Backups automÃ¡ticos (7-35 dÃ­as) âœ…   â”‚
â”‚ â€¢ Actualizaciones automÃ¡ticas âœ…       â”‚
â”‚ â€¢ Alta disponibilidad (99.99% SLA) âœ…  â”‚
â”‚ â€¢ Escalado de almacenamiento âœ…        â”‚
â”‚ â€¢ Seguridad (SSL forzado) âœ…           â”‚
â”‚ â€¢ Monitoreo 24/7 âœ…                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Azure Load Balancer

Distribuye trÃ¡fico entre mÃºltiples instancias.

```
Sin Load Balancer:
Usuario â†’ http://52.123.45.67:4000 â†’ Pod 1
                                      (si falla, usuario ve error âŒ)

Con Load Balancer:
Usuario â†’ http://backend-lb.azure.com
            â†“
    Azure Load Balancer
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”
    â–¼       â–¼       â–¼
  Pod 1   Pod 2   Pod 3
  
Si Pod 1 falla:
    â†“
Load Balancer detecta (health check)
    â†“
Redirige trÃ¡fico a Pod 2 y Pod 3 âœ…
    â†“
Usuario no nota la diferencia
```

---

## ğŸ”„ ComparaciÃ³n Final: EvoluciÃ³n de la Infraestructura

### Nivel 0: Sin Contenedores (Antiguo)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Tu Computadora                          â”‚
â”‚                                             â”‚
â”‚  PostgreSQL (instalado localmente)          â”‚
â”‚  Node.js (instalado localmente)             â”‚
â”‚  Backend (puerto 4000)                      â”‚
â”‚  Frontend (puerto 3000)                     â”‚
â”‚                                             â”‚
â”‚  Problemas:                                 â”‚
â”‚  â€¢ "Funciona en mi mÃ¡quina" â‰  en producciÃ³nâ”‚
â”‚  â€¢ Conflictos de versiones                  â”‚
â”‚  â€¢ DifÃ­cil de replicar                      â”‚
â”‚  â€¢ No portable                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Nivel 1: Con Docker

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Tu Computadora                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Docker Engine                         â”‚ â”‚
â”‚  â”‚                                        â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚PostgreSQLâ”‚  â”‚ Backend  â”‚  â”‚Frontendâ”‚â”‚ â”‚
â”‚  â”‚  â”‚Container â”‚  â”‚Container â”‚  â”‚Containerâ”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                             â”‚
â”‚  Mejoras:                                   â”‚
â”‚  â€¢ Portable âœ…                              â”‚
â”‚  â€¢ Aislado âœ…                               â”‚
â”‚  â€¢ Reproducible âœ…                          â”‚
â”‚  â€¢ Pero... solo en una mÃ¡quina âš ï¸          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Nivel 2: Con Docker Compose

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Tu Computadora                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Docker Compose                        â”‚ â”‚
â”‚  â”‚                                        â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚PostgreSQLâ”‚â—„â”€â”‚ Backend  â”‚â—„â”€â”‚Frontendâ”‚â”‚ â”‚
â”‚  â”‚  â”‚ +Volume  â”‚  â”‚ +Health  â”‚  â”‚ +Nginx â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â”‚       â”‚             â”‚            â”‚    â”‚ â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â”‚         pokemon_network (Bridge)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                             â”‚
â”‚  Mejoras:                                   â”‚
â”‚  â€¢ OrquestaciÃ³n simple âœ…                   â”‚
â”‚  â€¢ Un comando para iniciar todo âœ…          â”‚
â”‚  â€¢ Networking automÃ¡tico âœ…                 â”‚
â”‚  â€¢ Pero... solo desarrollo local âš ï¸        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Nivel 3: Con Kubernetes (Local)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Minikube (Cluster local)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Kubernetes                            â”‚ â”‚
â”‚  â”‚                                        â”‚ â”‚
â”‚  â”‚  Namespace: pokemon-app                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚ Deployment: backend (3 pods)    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Pod 1â”‚ â”‚Pod 2â”‚ â”‚Pod 3â”‚        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜        â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚               â”‚                        â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚ â”‚
â”‚  â”‚  â”‚ Service: LoadBalancer   â”‚          â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚ â”‚
â”‚  â”‚                                        â”‚ â”‚
â”‚  â”‚  PVC: postgres-pvc (1Gi)               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                             â”‚
â”‚  Mejoras:                                   â”‚
â”‚  â€¢ Escalado horizontal âœ…                   â”‚
â”‚  â€¢ Self-healing âœ…                          â”‚
â”‚  â€¢ Load balancing âœ…                        â”‚
â”‚  â€¢ Rolling updates âœ…                       â”‚
â”‚  â€¢ Pero... solo local âš ï¸                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Nivel 4: Con Kubernetes en Azure Cloud

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ AZURE CLOUD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  AKS (Kubernetes administrado)                       â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚  â”‚  Node 1  â”‚  â”‚  Node 2  â”‚  â”‚  Node 3  â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â”‚Pod B1â”‚ â”‚  â”‚ â”‚Pod B2â”‚ â”‚  â”‚ â”‚Pod B3â”‚ â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”‚  â”‚          â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â”‚Pod F â”‚ â”‚  â”‚ â”‚Pod P â”‚ â”‚  â”‚          â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚          â”‚          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚         â”‚             â”‚             â”‚                â”‚  â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚  â”‚
â”‚  â”‚                       â”‚                              â”‚  â”‚
â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚  â”‚
â”‚  â”‚              â”‚ Load Balancer   â”‚                     â”‚  â”‚
â”‚  â”‚              â”‚  (IP pÃºblica)   â”‚                     â”‚  â”‚
â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  Azure Database for PostgreSQL      â”‚                 â”‚
â”‚  â”‚  â€¢ Backups automÃ¡ticos               â”‚                 â”‚
â”‚  â”‚  â€¢ Alta disponibilidad               â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Azure Container Registry          â”‚                   â”‚
â”‚  â”‚  â€¢ pokemon-backend:v1              â”‚                   â”‚
â”‚  â”‚  â€¢ pokemon-frontend:v1             â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Internet (HTTPS)
                          â–¼
                   ğŸŒ Usuarios Globales
```

**Mejoras finales:**
âœ… Accesible 24/7 desde cualquier lugar  
âœ… Escalado automÃ¡tico (HPA)  
âœ… Alta disponibilidad multi-zona  
âœ… Backups automÃ¡ticos  
âœ… Actualizaciones sin downtime  
âœ… Monitoreo y alertas 24/7  
âœ… Disaster recovery  

---

## ğŸ“ Resumen Ejecutivo

### Conceptos Clave Aprendidos

1. **Contenedores (Docker)**: Empaquetar aplicaciones con todas sus dependencias
2. **OrquestaciÃ³n (Docker Compose)**: Gestionar mÃºltiples contenedores localmente
3. **OrquestaciÃ³n Avanzada (Kubernetes)**: Gestionar aplicaciones en producciÃ³n
4. **Cloud Computing (Azure)**: Infraestructura escalable y administrada

### Flujo Completo de Despliegue

```
1. Desarrollo Local
   â†“
   Escribir cÃ³digo (backend, frontend, database)
   â†“
2. ContenedorizaciÃ³n
   â†“
   Crear Dockerfiles
   â†“
3. Prueba Local
   â†“
   docker-compose up (3 servicios)
   â†“
4. OrquestaciÃ³n Kubernetes Local
   â†“
   minikube start â†’ kubectl apply -f kubernetes/
   â†“
5. Despliegue Cloud
   â†“
   Push a ACR â†’ Deploy a AKS â†’ Conectar a Azure PostgreSQL
   â†“
6. ProducciÃ³n
   â†“
   AplicaciÃ³n accesible globalmente 24/7
```

### Por QuÃ© Cada TecnologÃ­a

| TecnologÃ­a | Problema que Resuelve |
|------------|----------------------|
| **Docker** | "Funciona en mi mÃ¡quina" â‰  producciÃ³n |
| **Docker Compose** | Gestionar 3+ contenedores es tedioso |
| **Kubernetes** | Necesito escalabilidad y auto-recuperaciÃ³n |
| **Azure AKS** | Gestionar Kubernetes es complejo |
| **Azure ACR** | Necesito registry privado y rÃ¡pido |
| **Azure PostgreSQL** | Quiero BD administrada con backups |

### NÃºmeros del Proyecto

| MÃ©trica | Valor |
|---------|-------|
| **Contenedores** | 3 (postgres, backend, frontend) |
| **RÃ©plicas Backend** | 3 (alta disponibilidad) |
| **Pods totales** | 5 (3 backend + 1 frontend + 1 postgres) |
| **Nodos AKS** | 3 (distribuciÃ³n multi-zona) |
| **Uptime esperado** | 99.95% (SLA de Azure) |
| **Tiempo de recuperaciÃ³n** | 15 segundos (self-healing) |
| **Tiempo de escalado** | 30 segundos (3â†’5 rÃ©plicas) |

---

## ğŸš€ PrÃ³ximos Pasos Sugeridos

1. **Entender los manifiestos de Kubernetes**: Lee cada archivo `.yaml` en `kubernetes/`
2. **Experimentar con escalado**: `kubectl scale deployment backend --replicas=10`
3. **Simular fallos**: `kubectl delete pod <pod-name>` y ver cÃ³mo se recupera
4. **Explorar Azure**: Seguir la guÃ­a `GUIA_DESPLIEGUE_AZURE.md`
5. **Monitoreo**: Instalar Prometheus y Grafana en Kubernetes

---

**ğŸ¯ ConclusiÃ³n:** La infraestructura moderna es sobre **automatizaciÃ³n**, **escalabilidad** y **resiliencia**. Este proyecto demuestra cÃ³mo pasar de una aplicaciÃ³n local a una aplicaciÃ³n de nivel empresarial lista para producciÃ³n.

---

**Autor:** Proyecto Pokemon - Infraestructura  
**Fecha:** Diciembre 2025  
**VersiÃ³n:** 1.0
